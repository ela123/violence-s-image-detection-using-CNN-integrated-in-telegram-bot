{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "rMsSN-LN8OsF",
        "outputId": "90be2a2e-b01b-4b54-c6fa-58c76349f300"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7b37688c22ec>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m196608\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (32,)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(32,), dtype=uint8)\n      • training=False\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/pro1/myModel1.h5')\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/IMG_20210801_094533.jpg')\n",
        "img = cv2.resize(img,(256,256),3)\n",
        "img = np.reshape(img,[196608])\n",
        "\n",
        "classes = model.predict(img)\n",
        "\n",
        "print (classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnLQ4cbstfqj",
        "outputId": "646e2332-a5e0-487a-d42d-e20e2cddbb7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 311ms/step\n",
            "non\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture('path/to/video.mp4')\n",
        "\n",
        "# Initialize an empty list to store the frames\n",
        "frames = []\n",
        "\n",
        "# Loop through the frames\n",
        "while cap.isOpened():\n",
        "    # Read the next frame\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Add the frame to the list\n",
        "    frames.append(frame)\n",
        "\n",
        "# Release the video capture\n",
        "cap.release()\n",
        "\n",
        "# Convert the list of frames to a NumPy array\n",
        "frames = np.array(frames)\n",
        "# File path\n",
        "filepath = '/content/drive/MyDrive/datasetm/myModel1.h5'\n",
        "\n",
        "# Load the model\n",
        "model = load_model(filepath, compile = True)\n",
        "\n",
        "# A few random samples\n",
        "use_samples = [5, 38, 3939, 27389]\n",
        "samples_to_predict = []\n",
        "\n",
        "# Convert into Numpy array\n",
        "samples_to_predict = np.array(samples_to_predict)\n",
        "img = cv2.imread('/content/drive/MyDrive/Copy of M2225.jpg')\n",
        "img = cv2.resize(img,(256,256))\n",
        "img = np.array(img)\n",
        "# Reshape the image to have shape (1, 256, 256, 3)\n",
        "input_image = img.reshape((1, 256, 256, 3))\n",
        "# Generate predictions for samples\n",
        "predictions = model.predict(input_image)\n",
        "predictions=np.array(predictions)\n",
        "# print(predictions )\n",
        "# print(predictions.argmax(axis=1))\n",
        "\n",
        "\n",
        "arr = np.array(predictions)\n",
        "flat_arr = arr.flatten()\n",
        "\n",
        "# print(flat_arr)\n",
        "\n",
        "if flat_arr[0]==1:\n",
        "  print (\"non\")\n",
        "elif flat_arr[1]==1:\n",
        "  print (\"vi\")\n",
        "else :\n",
        "  print (\"worng format\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQxm_QLQTeDB",
        "outputId": "6ab86257-6f02-4795-da25-0d06b34ded8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = np.array(predictions)\n",
        "flat_arr = arr.flatten()\n",
        "\n",
        "print(flat_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly98L-b1Wq8S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeVS3Mt-ZYjS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOdx-BhOZawB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVz7EOyKaeKS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "                    level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Set up pre-trained image classification model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/datasetm/myModel1.h5')\n",
        "\n",
        "# Define a function to process a video\n",
        "def process_video(video_path):\n",
        "    # Read the video frames\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "\n",
        "    # Convert the list of frames to a NumPy array\n",
        "    frames = np.array(frames)\n",
        "\n",
        "    # Preprocess the frames for the model\n",
        "    input_data = []\n",
        "    for frame in frames:\n",
        "        # Resize the frame to match the input size of the model\n",
        "        resized_frame = cv2.resize(frame, (256, 256))\n",
        "\n",
        "        # Preprocess the frame for the model\n",
        "        input_frame = resized_frame.astype(np.float32)\n",
        "        input_frame = input_frame / 255.0\n",
        "\n",
        "        # Add the preprocessed frame to the input data\n",
        "        input_data.append(input_frame)\n",
        "    input_data = np.array(input_data)\n",
        "\n",
        "    # Run the model on the input data\n",
        "    predictions = model.predict(input_data)\n",
        "\n",
        "    # Return the result\n",
        "    if np.mean(predictions) > 0.5:\n",
        "        return 'This video contains a dog.'\n",
        "    else:\n",
        "        return 'This video contains a cat.'\n",
        "\n",
        "# Define a function to classify a video from its URL\n",
        "def classify_video_from_url(video_url):\n",
        "    # Download the video\n",
        "    r = requests.get(video_url, stream=True)\n",
        "    if r.status_code != 200:\n",
        "        logger.error('Error downloading video')\n",
        "        return None\n",
        "    video_path = '/content/drive/MyDrive/221.mp4'\n",
        "    with open(video_path, 'wb') as f:\n",
        "        for chunk in r.iter_content(1024):\n",
        "            f.write(chunk)\n",
        "\n",
        "    # Classify the video\n",
        "    result = process_video(video_path)\n",
        "\n",
        "    # Delete the video file\n",
        "    os.remove(video_path)\n",
        "\n",
        "    # Return the result\n",
        "    return result\n",
        "\n",
        "# Define a function to classify a video from a local file\n",
        "def classify_video_from_file(video_path):\n",
        "    # Classify the video\n",
        "    result = process_video(video_path)\n",
        "\n",
        "    # Return the result\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEJ62EC_9qwf"
      },
      "outputs": [],
      "source": [
        "img_path = '/content/drive/MyDrive/IMG_20210801_094533.jpg'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBczkUJo9ywG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO8uQ42y92Qu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oh9aC3BnHlnq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHgS5uQc95YW",
        "outputId": "466396a3-9b00-47c0-b818-43b37e8e5a87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 219ms/step\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYL_ZkI4HqKb",
        "outputId": "018dc0d7-41b2-4bab-a98d-5a7c80515b4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3909, done.\u001b[K\n",
            "remote: Counting objects: 100% (3909/3909), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3013/3013), done.\u001b[K\n",
            "remote: Total 3909 (delta 1129), reused 2002 (delta 843), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3909/3909), 49.65 MiB | 33.14 MiB/s, done.\n",
            "Resolving deltas: 100% (1129/1129), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --depth 1 https://github.com/tensorflow/models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VoXCs_795OH",
        "outputId": "b1a6345c-4986-4876-a602-c156113d4a4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ]
        }
      ],
      "source": [
        "%cd models/research"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 808
        },
        "id": "UiBzR4mn95LP",
        "outputId": "2a25e796-20f4-4a73-f9c2-6e935bc5e206"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Collecting protobuf\n",
            "  Downloading protobuf-4.23.2-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "Successfully installed protobuf-4.23.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n",
            "Collecting pillow\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "Successfully installed pillow-9.5.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pip\n",
        "!pip install -U protobuf\n",
        "!pip install -U pillow\n",
        "!pip install -U lxml\n",
        "!pip install -U matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K61yFn-U2yqT"
      },
      "outputs": [],
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpC6YcGO25JU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROEVpsMo2-Sy",
        "outputId": "95bb0eb6-6192-457a-c599-30c4a9f43f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-06-12 09:07:38.739715: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 24, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "  File \"/content/models/research/object_detection/builders/model_builder.py\", line 23, in <module>\n",
            "    from object_detection.builders import anchor_generator_builder\n",
            "  File \"/content/models/research/object_detection/builders/anchor_generator_builder.py\", line 26, in <module>\n",
            "    from object_detection.protos import anchor_generator_pb2\n",
            "  File \"/content/models/research/object_detection/protos/anchor_generator_pb2.py\", line 15, in <module>\n",
            "    from object_detection.protos import flexible_grid_anchor_generator_pb2 as object__detection_dot_protos_dot_flexible__grid__anchor__generator__pb2\n",
            "  File \"/content/models/research/object_detection/protos/flexible_grid_anchor_generator_pb2.py\", line 35, in <module>\n",
            "    _descriptor.FieldDescriptor(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/protobuf/descriptor.py\", line 561, in __new__\n",
            "    _message.Message._CheckCalledFromGeneratedFile()\n",
            "TypeError: Descriptors cannot not be created directly.\n",
            "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
            "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
            " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
            " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
            "\n",
            "More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n"
          ]
        }
      ],
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy_sICDL3BJq",
        "outputId": "93da621c-4ccc-4fc6-eb28-19dfb0d8f3b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ],
      "source": [
        "pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwMe9cHB8Rj8",
        "outputId": "735ea585-8a58-4f62-c4e4-e5a021510b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8CwzjmB8ZCs"
      },
      "outputs": [],
      "source": [
        "from keras.applications.resnet50 import ResNet50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3KIDqwcXlSS"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import cv2\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/221.mp4')\n",
        "filepath2 = '/content/drive/MyDrive/pro1/myModel1.h5'\n",
        "model = load_model(filepath2, compile = True)\n",
        "# Initialize an empty list to store the frames\n",
        "frames = []\n",
        "intvl = 1.9\n",
        "# Loop through the frames\n",
        "fps= int(cap.get(cv2.CAP_PROP_FPS))\n",
        "print(\"fps : \" ,fps)\n",
        "\n",
        "currentframe = 0\n",
        "while (True):\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        if(currentframe % (fps*intvl) == 0):\n",
        "            name =  str(currentframe) + '.jpg'\n",
        "            # print('Creating...' + name)\n",
        "            # cv2.imwrite(name, frame)\n",
        "        currentframe += 1\n",
        "        frames.append(frame)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "\n",
        "# Release the video capture\n",
        "cap.release()\n",
        "# print(len(frames))\n",
        "# Convert the list of frames to a NumPy array\n",
        "# frames = np.array(frames)\n",
        "# Preprocess the frames for the model\n",
        "checkvi=[]\n",
        "input_data = []\n",
        "count=0\n",
        "for frame in frames:\n",
        "        # Resize the frame to match the input size of the model\n",
        "        resized_frame = cv2.resize(frame, (256, 256))\n",
        "        resized_frame = np.array(resized_frame)\n",
        "        # Preprocess the frame for the model\n",
        "        input_frame = resized_frame.reshape((1, 256, 256, 3))\n",
        "        predictions = model.predict(input_frame)\n",
        "        # print(predictions)\n",
        "        # Add the preprocessed frame to the input data\n",
        "        input_data.append(input_frame)\n",
        "        predictions=np.array(predictions)\n",
        "        # print(predictions)\n",
        "        # print(np.shape(predictions))\n",
        "        arr2 = np.array(predictions)\n",
        "        flat_arr2 = arr2.flatten()\n",
        "\n",
        "\n",
        "        if flat_arr2[0]==1:\n",
        "                cub=1\n",
        "        elif flat_arr2[1]==1:\n",
        "             count=count+1\n",
        "             checkvi.append(count)\n",
        "        else:\n",
        "          ela=1\n",
        "if count >= fps/5:\n",
        "  print('This is vi image!')\n",
        "else:\n",
        "  print('This is non  image!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDRUuS-HwgW3",
        "outputId": "0260867f-0bf4-4f54-e6ea-c3e867edf220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-telegram-bot==13.14 in /usr/local/lib/python3.10/dist-packages (13.14)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.14) (2022.12.7)\n",
            "Requirement already satisfied: tornado==6.1 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.14) (6.1)\n",
            "Requirement already satisfied: APScheduler==3.6.3 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.14) (3.6.3)\n",
            "Requirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.14) (2022.7.1)\n",
            "Requirement already satisfied: cachetools==4.2.2 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.14) (4.2.2)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.14) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.14) (1.16.0)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.14) (4.3)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal>=1.2->APScheduler==3.6.3->python-telegram-bot==13.14) (0.1.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal>=1.2->APScheduler==3.6.3->python-telegram-bot==13.14) (2023.3)\n"
          ]
        }
      ],
      "source": [
        "pip install python-telegram-bot==13.14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIi0cCcJD4mr",
        "outputId": "c5021601-f59b-4116-e420-1e04a8d61f58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:telegram.ext.dispatcher:No error handlers are registered, logging exception.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/telegram/ext/dispatcher.py\", line 557, in process_update\n",
            "    handler.handle_update(update, self, check, context)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/telegram/ext/handler.py\", line 199, in handle_update\n",
            "    return self.callback(update, context)\n",
            "  File \"<ipython-input-3-aac71acc5ed8>\", line 29, in handle_video\n",
            "    video_file = update.get_file(video_file_id)\n",
            "AttributeError: 'Update' object has no attribute 'get_file'\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import telegram\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "from telegram.ext import Updater, MessageHandler, Filters\n",
        "import numpy as np\n",
        "import telegram\n",
        "bot = telegram.Bot(token=\"5835256859:AAGj4BboS6H2q72PC8zfMZxr9bNgJO_KZ80\")\n",
        "# Set up logging\n",
        "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "                     level=logging.INFO)\n",
        "\n",
        "# File path\n",
        "filepath = '/content/drive/MyDrive/pro1/myModel1.h5'\n",
        "model = load_model(filepath, compile = True)\n",
        "\n",
        "def handle_video(update, context):\n",
        "   # Get the video file ID.\n",
        "    video_file_id = update.message.video.file_id\n",
        "\n",
        "    # Get the video file object.\n",
        "    video_file = update.get_file(video_file_id)\n",
        "\n",
        "    # Download the video file.\n",
        "    video_path = \"video.mp4\"\n",
        "    video_file.download(video_path)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    filepath2 = '/content/drive/MyDrive/pro1/myModel1.h5'\n",
        "    model = load_model(filepath2, compile = True)\n",
        "    # Initialize an empty list to store the frames\n",
        "    frames = []\n",
        "    intvl = 1.9\n",
        "    # Loop through the frames\n",
        "    fps= int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    print(\"fps : \" ,fps)\n",
        "\n",
        "    currentframe = 0\n",
        "    while (True):\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            if(currentframe % (fps*intvl) == 0):\n",
        "                name =  str(currentframe) + '.jpg'\n",
        "                # print('Creating...' + name)\n",
        "                # cv2.imwrite(name, frame)\n",
        "            currentframe += 1\n",
        "            frames.append(frame)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "\n",
        "    # Release the video capture\n",
        "    cap.release()\n",
        "    # print(len(frames))\n",
        "    # Convert the list of frames to a NumPy array\n",
        "    # frames = np.array(frames)\n",
        "    # Preprocess the frames for the model\n",
        "    checkvi=[]\n",
        "    input_data = []\n",
        "    count=0\n",
        "    for frame in frames:\n",
        "            # Resize the frame to match the input size of the model\n",
        "            resized_frame = cv2.resize(frame, (256, 256))\n",
        "            resized_frame = np.array(resized_frame)\n",
        "            # Preprocess the frame for the model\n",
        "            input_frame = resized_frame.reshape((1, 256, 256, 3))\n",
        "            predictions = model.predict(input_frame)\n",
        "            # print(predictions)\n",
        "            # Add the preprocessed frame to the input data\n",
        "            input_data.append(input_frame)\n",
        "            predictions=np.array(predictions)\n",
        "            # print(predictions)\n",
        "            # print(np.shape(predictions))\n",
        "            arr2 = np.array(predictions)\n",
        "            flat_arr2 = arr2.flatten()\n",
        "\n",
        "\n",
        "            if flat_arr2[0]==1:\n",
        "                    cub=1\n",
        "            elif flat_arr2[1]==1:\n",
        "                count=count+1\n",
        "                checkvi.append(count)\n",
        "            else:\n",
        "              ela=1\n",
        "    if count >= fps/5:\n",
        "      context.bot.send_message(chat_id=update.message.chat_id, text=\"'This is vi image!'\")\n",
        "    else:\n",
        "      context.bot.send_message(chat_id=update.message.chat_id, text=\"'This is non violance image!'\")\n",
        "\n",
        "\n",
        "# Create a bot and add the message handler\n",
        "updater = Updater(token='5835256859:AAGj4BboS6H2q72PC8zfMZxr9bNgJO_KZ80', use_context=True)\n",
        "dispatcher = updater.dispatcher\n",
        "dispatcher.add_handler(MessageHandler(Filters.video, handle_video))\n",
        "\n",
        "# Start the bot\n",
        "updater.start_polling()\n",
        "updater.idle()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}